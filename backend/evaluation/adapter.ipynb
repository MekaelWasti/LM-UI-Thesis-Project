{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import openai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../apiKey.env\")\n",
    "OPENAI_API_KEY = os.getenv(\"API_KEY\")\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generation():\n",
    "  # response = openai.ChatCompletion.create(\n",
    "  response = client.chat.completions.create(\n",
    "  # model=\"gpt-3.5-turbo\",\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      # \"content\": \"Formulate prompts that state a clear mathematical operation in words or symbols. format prompt || expression\\n\\nGenerate with a mix of concepts as below \\n\\nSimple Arithmetic:\\n\\\"Add 7 to 15.\\\" || \\\"7 + 15\\\"\\nCompound Operations:\\n\\\"First multiply 4 by 3, then add 7.\\\" || \\\"(4 * 3) + 7\\\"\\nUse of Brackets:\\n\\\"Add 3 to 8, and then multiply the result by 2.\\\" || \\\"(3 + 8) * 2\\\"\\nWord Problems:\\n\\\"If you have 20 apples and give away 5, how many are left?\\\" || \\\"20 - 5\\\"\\n Keep a consistant format. Don't number the results\"\n",
    "      \"content\": \"Formulate prompts that state a clear mathematical operation in words or symbols. format prompt || expression\\n\\nGenerate with a mix of concepts as below \\n\\nSimple Arithmetic:\\n\\\"Add 7 to 15.\\\" || \\\"7 + 15\\\"\\nCompound Operations:\\n\\\"First multiply 4 by 3, then add 7.\\\" || \\\"(4 * 3) + 7\\\", \\\"Show me 14 * 219 and add 10\\\"\\nUse of Brackets:\\n\\\"Add 3 to 8, and then multiply the result by 2.\\\" || \\\"(3 + 8) * 2\\\"\\n\\\" || \\\"20 - 5\\\"\\n Keep a consistant format: \\\"[prompt question]\\\" || \\\"[extracted expression]\\\" Don't number the results\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Generate 15 calculator app prompts.\"\n",
    "    },\n",
    "  ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=1066,\n",
    "  top_p=1,\n",
    "  frequency_penalty=1.22,\n",
    "  presence_penalty=1.07\n",
    "  )\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 1\n",
    "\n",
    "for n in range(iterations):\n",
    "    # res = generation()['choices'][0]['message']['content']\n",
    "    res = generation().choices[0].message.content\n",
    "    with open('calcFineTune_2.txt', 'a', encoding='utf-8') as file:\n",
    "        file.write(res)\n",
    "\n",
    "res = generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is for v1 of the openai package: pypi.org/project/openai\n",
    "def generation():\n",
    "  response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You are a dataset generator that helps me make my datasets for my fine-tuning of transformer large language models. I give you example prompts and you make prompts in the exact format but with different content so I can make a large dataset to fine-tune my models on.\\n\\n\\n\\\"Hi! I'm Olivia Peterson. You can mail me at 963 Walnut Grove, Meadowlands or email me at olivia.p@emailservice.com.\\\" || \\\"Address\\\": \\\"963 Walnut Grove, Meadowlands\\\"\\n\\n\\\"This is David Lee's contact information: Residential address is 147 Cedar Place, Highland Park; Email ID is davidlee@inbox.com.\\\" || \\\"Address\\\": \\\"147 Cedar Place, Highland Park\\\"\\n\\n\\\"My contact details are as follows: Name - Rachel Kim, Living at 369 Maplewood Drive, Sunnyvale; My primary email is rachel.k@webmail.co.\\\" || \\\"Address\\\": \\\"369 Maplewood Drive, Sunnyvale\\\"\\n\\n\\\"I am Brian O'Connor residing at Apartment 5A, 654 Peachtree Street in New Town and my email address is brian.oconnor@mailservice.net.\\\" || \\\"Address\\\": \\\"Apartment 5A, 654 Peachtree Street in New Town\\\"\\n\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Generate 6 prompts like I gave you\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\\\"Hello! I'm Sarah Johnson. You can reach me at 123 Oakwood Lane, Riverside or email me at sarah.johnson@emailservice.com.\\\" || \\\"Address\\\": \\\"123 Oakwood Lane, Riverside\\\"\\n\\n\\\"Here are the contact details for Michael Anderson: He lives at 789 Elm Street, Lexington; You can email him at michael.anderson@inbox.com.\\\" || \\\"Address\\\": \\\"789 Elm Street, Lexington\\\"\\n\\n\\\"I go by the name Emily Davis and my contact information is as follows: I reside at 456 Pine Avenue, Mountain View; Feel free to send me an email at emily.davis@webmail.co.\\\" || \\\"Address\\\": \\\"456 Pine Avenue, Mountain View\\\"\\n\\n\\\"I'm Thomas Miller. You can find me at 852 Willow Lane, Springville or email me at thomas.miller@emailservice.com.\\\" || \\\"Address\\\": \\\"852 Willow Lane, Springville\\\"\\n\\n\\\"Contact information for Jessica Martinez: She lives at 369 Oak Street, Riverdale; Her email ID is jessica.martinez@inbox.com.\\\" || \\\"Address\\\": \\\"369 Oak Street, Riverdale\\\"\\n\\n\\\"Let me introduce myself - I'm Daniel Brown. You can reach me at 741 Birch Avenue, Hillside or email me at daniel.brown@webmail.co.\\\" || \\\"Address\\\": \\\"741 Birch Avenue, Hillside\\\"\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Generate 10 more prompts, Don't say anything and don't number the responses\"\n",
    "    },\n",
    "  ],\n",
    "  temperature=1.09,\n",
    "  max_tokens=2400,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.5,\n",
    "  presence_penalty=0.5\n",
    ")\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is for v1 of the openai package: pypi.org/project/openai\n",
    "def generation():\n",
    "  response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You are a dataset generator that helps me make my datasets for my fine-tuning of transformer large language models. I give you example prompts and you make prompts in the exact format but with different content so I can make a large dataset to fine-tune my models on.\\n\\n\\n\\\"Hi! I'm Olivia Peterson. You can mail me at 963 Walnut Grove, Meadowlands or email me at olivia.p@emailservice.com.\\\" || \\\"Email\\\": \\\"olivia.p@emailservice.com\\\"\\n\\n\\\"This is David Lee's contact information: Residential address is 147 Cedar Place, Highland Park; Email ID is davidlee@inbox.com.\\\" || \\\"Email\\\": \\\"davidlee@inbox.com\\\"\\n\\n\\\"My contact details are as follows: Name - Rachel Kim, Living at 369 Maplewood Drive, Sunnyvale; My primary email is rachel.k@webmail.co.\\\" || \\\"Email\\\": \\\"rachel.k@webmail.co\\\"\\n\\n\\\"I am Brian O'Connor residing at Apartment 5A, 654 Peachtree Street in New Town and my email address is brian.oconnor@mailservice.net.\\\" || \\\"Email\\\": \\\"brian.oconnor@mailservice.net\\\"\\n\\nMake sure to mix up the order of where the email is in the statement\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Generate 6 prompts like I gave you\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\\\"You can reach me, Jessica Baker, at 221 Pine Lane, Greenhill. Alternatively, you can drop me an email at jessica.baker@emailhub.com.\\\" || \\\"Email\\\": \\\"jessica.baker@emailhub.com\\\"\\n\\\"If you need to get in touch with me, please contact 832 Oak Avenue, Riverside or email me at michael.w@protonmail.com. My name is Michael Williams.\\\" || \\\"Email\\\": \\\"michael.w@protonmail.com\\\"\\n\\\"Contact information for Sarah Johnson: Email - sarah.johnson@globalmail.org; Residential address - 580 Elm Street, Hillside.\\\" || \\\"Email\\\": \\\"sarah.johnson@globalmail.org\\\"\\n\\\"Feel free to drop me a message at luke_t@yahoo.com if you have any questions about the event! I can also be reached at 115 Willow Road, Westbrook. Name's Luke Turner.\\\" || \\\"Email\\\": \\\"luke_t@yahoo.com\\\"\\n\\\"To get in touch with me regarding the project, you can email me at eleanor.r@emailworld.net or visit my office at Suite 8B, 729 Parkside Avenue, Beacon Hills. I'm Eleanor Rogers.\\\" || \\\"Email\\\": \\\"eleanor.r@emailworld.net\\\"\\n\\\"My residential address is 945 Cedar Lane, Oak Valley and my primary email is carl.miller@postmail.com. You can contact Carl Miller using this information.\\\" || \\\"Email\\\": \\\"carl.miller@postmail.com\\\"\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Generate 10 more prompts. Don't say anything and don't number the responses. Make SURE the format is like this \\\"{statement containing name emaila in various orders}\\\" || \\\"Email\\\": \\\"{extracted email}\\\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=1.09,\n",
    "  max_tokens=2410,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.5,\n",
    "  presence_penalty=0.5\n",
    ")\n",
    "  return response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import openai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../apiKey.env\")\n",
    "OPENAI_API_KEY = os.getenv(\"API_KEY\")\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "# This code is for v1 of the openai package: pypi.org/project/openai\n",
    "def generation():\n",
    "  response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You are a dataset generator that helps me make my datasets for my fine-tuning of transformer large language models. I give you example prompts and you make prompts in the exact format but with different content so I can make a large dataset to fine-tune my models on.\\n\\n\\n\\\"Hi! I'm Olivia Peterson. You can mail me at 963 Walnut Grove, Meadowlands or email me at olivia.p@emailservice.com.\\\" || \\\"Email\\\": \\\"olivia.p@emailservice.com\\\"\\n\\n\\\"This is David Lee's contact information: Residential address is 147 Cedar Place, Highland Park; Email ID is davidlee@inbox.com.\\\" || \\\"Email\\\": \\\"davidlee@inbox.com\\\"\\n\\n\\\"My contact details are as follows: Name - Rachel Kim, Living at 369 Maplewood Drive, Sunnyvale; My primary email is rachel.k@webmail.co.\\\" || \\\"Email\\\": \\\"rachel.k@webmail.co\\\"\\n\\n\\\"I am Brian O'Connor residing at Apartment 5A, 654 Peachtree Street in New Town and my email address is brian.oconnor@mailservice.net.\\\" || \\\"Email\\\": \\\"brian.oconnor@mailservice.net\\\"\\n\\nMake sure to mix up the order of where the email is in the statement\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Generate 6 prompts like I gave you\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\\\"You can reach me, Jessica Baker, at 221 Pine Lane, Greenhill. Alternatively, you can drop me an email at jessica.baker@emailhub.com.\\\" || \\\"Email\\\": \\\"jessica.baker@emailhub.com\\\"\\n\\\"If you need to get in touch with me, please contact 832 Oak Avenue, Riverside or email me at michael.w@protonmail.com. My name is Michael Williams.\\\" || \\\"Email\\\": \\\"michael.w@protonmail.com\\\"\\n\\\"Contact information for Sarah Johnson: Email - sarah.johnson@globalmail.org; Residential address - 580 Elm Street, Hillside.\\\" || \\\"Email\\\": \\\"sarah.johnson@globalmail.org\\\"\\n\\\"Feel free to drop me a message at luke_t@yahoo.com if you have any questions about the event! I can also be reached at 115 Willow Road, Westbrook. Name's Luke Turner.\\\" || \\\"Email\\\": \\\"luke_t@yahoo.com\\\"\\n\\\"To get in touch with me regarding the project, you can email me at eleanor.r@emailworld.net or visit my office at Suite 8B, 729 Parkside Avenue, Beacon Hills. I'm Eleanor Rogers.\\\" || \\\"Email\\\": \\\"eleanor.r@emailworld.net\\\"\\n\\\"My residential address is 945 Cedar Lane, Oak Valley and my primary email is carl.miller@postmail.com. You can contact Carl Miller using this information.\\\" || \\\"Email\\\": \\\"carl.miller@postmail.com\\\"\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Generate 10 more prompts. Don't say anything other than the prompts and don't number the responses. Make SURE the format is like this \\\"{statement containing name address and emails in various orders}\\\" || \\\"Email\\\": \\\"{extracted email}\\\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=1.09,\n",
    "  max_tokens=2410,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.5,\n",
    "  presence_penalty=0.5\n",
    ")\n",
    "  return response\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "iterations = 40\n",
    "\n",
    "for n in range(iterations):\n",
    "    # res = generation()['choices'][0]['message']['content']\n",
    "    res = generation().choices[0].message.content\n",
    "    with open('EmailTune_1.txt', 'a', encoding='utf-8') as file:\n",
    "        file.write(res +\"\\n\")\n",
    "\n",
    "res = generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import openai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../apiKey.env\")\n",
    "OPENAI_API_KEY = os.getenv(\"API_KEY\")\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def generation():\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    messages=[\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a dataset generator that helps me make my datasets for my fine-tuning of transformer large language models. I give you example prompts and you make prompts in the exact format but with different content so I can make a large dataset to fine-tune my models on. Do not number the responses\\n\\n\\n\\\"What's the weather like in Vancouver, Canada?\\\" || \\\"Location\\\": \\\"Vancouver, Canada\\\"\\n\\n\\\"Show me the current weather in Tokyo, Japan.\\\" || \\\"Location\\\": \\\"Tokyo, Japan\\\"\\n\\n\\\"I need the wind speed for Berlin, Germany, right now.\\\" || \\\"Location\\\": \\\"Berlin, Germany\\\"\\n\\n\\\"What's the temperature in Rome, Italy, at the moment?\\\" || \\\"Location\\\": \\\"Rome, Italy\\\"\\n\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Generate 6 prompts like I gave you. Make sure to add variety, especially in the locations. Keep the format EXACTLY how I showed you with same number of spaces and placement of quotations\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\\\"Can you tell me the weather forecast for Sydney, Australia?\\\" || \\\"Location\\\": \\\"Sydney, Australia\\\"\\n\\n\\\"I'm curious about the current conditions in Paris, France. Can you provide that information?\\\" || \\\"Location\\\": \\\"Paris, France\\\"\\n\\n\\\"What's the weather like in New Delhi, India, right now?\\\" || \\\"Location\\\": \\\"New Delhi, India\\\"\\n\\n\\\"I need to know the humidity levels in London, England. Could you look that up for me?\\\" || \\\"Location\\\": \\\"London, England\\\"\\n\\n\\\"Could you show me the weather forecast for Cape Town, South Africa?\\\" || \\\"Location\\\": \\\"Cape Town, South Africa\\\"\\n\\n\\\"I'm interested in finding out the wind direction in Oslo, Norway. Can you help with that?\\\" || \\\"Location\\\": \\\"Oslo, Norway\\\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Generate 10 more prompts\"\n",
    "    }\n",
    "    ],\n",
    "    temperature=0.79,\n",
    "    max_tokens=2410,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0.5,\n",
    "    presence_penalty=0.5\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "iterations = 100\n",
    "\n",
    "for n in range(iterations):\n",
    "    # res = generation()['choices'][0]['message']['content']\n",
    "    res = generation().choices[0].message.content\n",
    "    with open('weatherTune.txt', 'a', encoding='utf-8') as file:\n",
    "        file.write(res +\"\\n\")\n",
    "\n",
    "res = generation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINE TUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r adapter_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import transformers\n",
    "from transformers import BertTokenizer, AutoTokenizer, AutoModelForSeq2SeqLM, BertForQuestionAnswering, AdapterConfig, AdapterType, T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "from transformers.adapters import AdapterArguments, AdapterTrainer, AutoAdapterModel, setup_adapter_training\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version\n",
    "from transformers.utils.versions import require_version\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained(\"deepset/bert-large-uncased-whole-word-masking-squad2\")\n",
    "# model = BertForQuestionAnswering.from_pretrained(\"deepset/bert-large-uncased-whole-word-masking-squad2\")\n",
    "\n",
    "modelName = \"google/flan-t5-large\"\n",
    "modelName = \"google/flan-t5-base\"\n",
    "modelName = \"google/flan-t5-small\"\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(modelName)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(modelName)\n",
    "\n",
    "# Add a new adapter for arithmetic expressions\n",
    "config = AdapterConfig.load(\"houlsby\", non_linearity=\"gelu\", reduction_factor=16)\n",
    "# model.add_adapter(\"arithmetic_expressionV2\", config=config)\n",
    "model.to('cuda')\n",
    "# model.train_adapter(\"arithmetic_expressionV2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "data = []\n",
    "with open(\"calcFineTune.txt\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    # print(line)\n",
    "    x = line.split(\"||\")\n",
    "\n",
    "    dataDict = {'prompt': x[0], 'expression': x[1]}\n",
    "    data.append(dataDict)\n",
    "\n",
    "data\n",
    "# data = json.dumps(data,indent=4)\n",
    "# with open(\"calcFineTuneDataJSON\", 'w') as file:\n",
    "    # json.dump(data, file, indent=4)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArithmeticDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        prompt = \"Extract arithmetic expression: \" + item['prompt'].strip()\n",
    "        expression = item['expression'].strip()\n",
    "\n",
    "        tokenized_input = self.tokenizer(prompt, max_length=self.max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "        tokenized_output = self.tokenizer(expression, max_length=self.max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": tokenized_input.input_ids.squeeze(),\n",
    "            \"attention_mask\": tokenized_input.attention_mask.squeeze(),\n",
    "            \"labels\": tokenized_output.input_ids.squeeze()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_batch(batch):\n",
    "    input_ids = [item['input_ids'] for item in batch]\n",
    "    attention_masks = [item['attention_mask'] for item in batch]\n",
    "    labels = [item['labels'] for item in batch]\n",
    "\n",
    "    input_ids = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    attention_masks = pad_sequence(attention_masks, batch_first=True, padding_value=0)\n",
    "    labels = pad_sequence(labels, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_masks,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "# Use this collate function in your DataLoader\n",
    "dataset = ArithmeticDataset(data, tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader:\n",
    "    print(batch['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids, attention_mask, labels = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():  # Disable gradient tracking\n",
    "    # Encode the prompt to token ids\n",
    "    # token = tokenizer.encode(\"Extract arithmetic expression: \\\"can you do 3 plus 40 multiplied by 310\\\"\", return_tensors='pt', max_length=max_length, truncation=True).to(\"cuda\")\n",
    "    token = tokenizer.encode(\"Extract arithmetic expression: \\\"Subtract 8 from 42\\\"\", return_tensors='pt', max_length=50, truncation=True).to(\"cuda\")\n",
    "    print(token)\n",
    "    # Generate the output sequence\n",
    "    output_sequences = model.generate(input_ids=token, max_length=50)  # You can adjust max_length as needed\n",
    "    print(output_sequences)\n",
    "    # Decode the output to text\n",
    "    output_text = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "\n",
    "    print(\"Extracted Expression:\", output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_adapter(\"./arithmetic_adapter\", \"arithmetic_expression\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "# path = \"/content/drive/My Drive/My_Models/gpt1\"\n",
    "path = '/content/gdrive/My Drive/thesis-T5/'\n",
    "\n",
    "# Or for PyTorch, save just the state_dict:\n",
    "# torch.save(model.state_dict(), f'{path}/adapter_weights.pth')\n",
    "model.save_adapter(\"./arithmetic_adapter\", \"arithmetic_expression\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
