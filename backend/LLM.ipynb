{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Brendan', 'Jackson'), ('Jackson', 'Mekael'), ('Mekael', 'Eve'), ('Eve', 'Brendan')]\n"
     ]
    }
   ],
   "source": [
    "from itertools import cycle\n",
    "import random\n",
    "names = [\"Mekael\", \"Brendan\", \"Eve\", \"Jackson\"]\n",
    "random.shuffle(names)\n",
    "circular_names = cycle(names)\n",
    "next(circular_names)\n",
    "circular_pairs = [(names[i], next(circular_names)) for i in range(len(names))]\n",
    "print(circular_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Configuration and Split\n",
    "dataset = load_dataset(\"glue\",\"stsb\")\n",
    "trainDataset = dataset[\"train\"]\n",
    "validationDataset = dataset[\"validation\"]\n",
    "testDataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels = 1)\n",
    "model = model.to(device)\n",
    "\n",
    "text = \"Didn't get here being careful\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt').to(device)\n",
    "output = model(**encoded_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize Datasets Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeFunction(data):\n",
    "    return tokenizer(data['sentence1'],data['sentence2'], truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizedTrainDataset = trainDataset.map(tokenizeFunction, batched = True)\n",
    "tokenizedValidationDataset = validationDataset.map(tokenizeFunction, batched = True)\n",
    "tokenizedTestDataset = testDataset.map(tokenizeFunction, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizedTrainDataset = tokenizedTrainDataset.map(lambda batch: {'input_ids': batch['input_ids'], 'attention_mask': batch['attention_mask'], 'labels': batch['label']}, remove_columns=['sentence1', 'sentence2', 'label', 'idx'])\n",
    "tokenizedValidationDataset = tokenizedValidationDataset.map(lambda batch: {'input_ids': batch['input_ids'], 'attention_mask': batch['attention_mask'], 'labels': batch['label']}, remove_columns=['sentence1', 'sentence2', 'label', 'idx'])\n",
    "tokenizedTestDataset = tokenizedTestDataset.map(lambda batch: {'input_ids': batch['input_ids'], 'attention_mask': batch['attention_mask'], 'labels': batch['label']}, remove_columns=['sentence1', 'sentence2', 'label', 'idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 5749\n",
       "})"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizedTrainDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 1500\n",
       "})"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizedValidationDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "checkpoint_dir = './results/checkpoint-7000'  # Replace with your checkpoint directory\n",
    "\n",
    "trainer_state_path = os.path.join(checkpoint_dir, 'trainer_state.json')\n",
    "\n",
    "with open(trainer_state_path, 'r') as f:\n",
    "    trainer_state = json.load(f)\n",
    "\n",
    "last_epoch = trainer_state['epoch']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Training Arguments\n",
    "trainingArgs = TrainingArguments(\n",
    "    output_dir= \"./results\",\n",
    "    num_train_epochs= last_epoch + 6,\n",
    "    per_device_eval_batch_size= 8,\n",
    "    per_device_train_batch_size= 8,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy= \"epoch\",\n",
    "    logging_dir = \"./logs\",\n",
    "    logging_steps=100,\n",
    "    do_train = True,\n",
    "    do_eval = True,\n",
    "    learning_rate = 5e-5,\n",
    ")\n",
    "\n",
    "# Configure Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    \n",
    "    args=trainingArgs,\n",
    "    train_dataset=tokenizedTrainDataset,\n",
    "    eval_dataset= tokenizedValidationDataset,\n",
    "    compute_metrics=lambda eval_preds: {\"mse\": ((eval_preds.predictions - eval_preds.label_ids) ** 2).mean()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a675405c440e48d9bbacd5649f58e745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7814 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2706, 'learning_rate': 5e-05, 'epoch': 0.14}\n",
      "{'loss': 0.4034, 'learning_rate': 4.935182784547576e-05, 'epoch': 0.28}\n",
      "{'loss': 0.349, 'learning_rate': 4.8703655690951524e-05, 'epoch': 0.42}\n",
      "{'loss': 0.2987, 'learning_rate': 4.8055483536427274e-05, 'epoch': 0.56}\n",
      "{'loss': 0.3105, 'learning_rate': 4.740731138190304e-05, 'epoch': 0.7}\n",
      "{'loss': 0.3103, 'learning_rate': 4.6759139227378796e-05, 'epoch': 0.83}\n",
      "{'loss': 0.2309, 'learning_rate': 4.611096707285455e-05, 'epoch': 0.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a81f91bd42949b5b6fd1acc59f23289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.665998101234436, 'eval_mse': 4.747801303863525, 'eval_runtime': 14.614, 'eval_samples_per_second': 102.641, 'eval_steps_per_second': 12.864, 'epoch': 1.0}\n",
      "{'loss': 0.2547, 'learning_rate': 4.546279491833031e-05, 'epoch': 1.11}\n",
      "{'loss': 0.3169, 'learning_rate': 4.481462276380607e-05, 'epoch': 1.25}\n",
      "{'loss': 0.236, 'learning_rate': 4.416645060928183e-05, 'epoch': 1.39}\n",
      "{'loss': 0.2766, 'learning_rate': 4.351827845475759e-05, 'epoch': 1.53}\n",
      "{'loss': 0.2689, 'learning_rate': 4.287010630023334e-05, 'epoch': 1.67}\n",
      "{'loss': 0.2696, 'learning_rate': 4.2221934145709104e-05, 'epoch': 1.81}\n",
      "{'loss': 0.2856, 'learning_rate': 4.157376199118486e-05, 'epoch': 1.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d06ddc043967440c90de7f6291e79273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5439280867576599, 'eval_mse': 4.394655227661133, 'eval_runtime': 19.6004, 'eval_samples_per_second': 76.529, 'eval_steps_per_second': 9.592, 'epoch': 2.0}\n",
      "{'loss': 0.234, 'learning_rate': 4.092558983666062e-05, 'epoch': 2.09}\n",
      "{'loss': 0.2145, 'learning_rate': 4.0277417682136376e-05, 'epoch': 2.23}\n",
      "{'loss': 0.2034, 'learning_rate': 3.9629245527612133e-05, 'epoch': 2.36}\n",
      "{'loss': 0.2223, 'learning_rate': 3.89810733730879e-05, 'epoch': 2.5}\n",
      "{'loss': 0.2042, 'learning_rate': 3.8332901218563655e-05, 'epoch': 2.64}\n",
      "{'loss': 0.2487, 'learning_rate': 3.768472906403941e-05, 'epoch': 2.78}\n",
      "{'loss': 0.2753, 'learning_rate': 3.703655690951517e-05, 'epoch': 2.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f775e083a5241a5ac1635455550e30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5000523924827576, 'eval_mse': 4.338993549346924, 'eval_runtime': 541.55, 'eval_samples_per_second': 2.77, 'eval_steps_per_second': 0.347, 'epoch': 3.0}\n",
      "{'loss': 0.2404, 'learning_rate': 3.638838475499093e-05, 'epoch': 3.06}\n",
      "{'loss': 0.199, 'learning_rate': 3.574021260046669e-05, 'epoch': 3.2}\n",
      "{'loss': 0.2057, 'learning_rate': 3.509204044594244e-05, 'epoch': 3.34}\n",
      "{'loss': 0.2292, 'learning_rate': 3.44438682914182e-05, 'epoch': 3.48}\n",
      "{'loss': 0.2141, 'learning_rate': 3.379569613689396e-05, 'epoch': 3.62}\n",
      "{'loss': 0.2163, 'learning_rate': 3.314752398236972e-05, 'epoch': 3.76}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[229], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m      2\u001b[0m trainer\u001b[39m.\u001b[39mevaluate()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\trainer.py:1553\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1554\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1555\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1556\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1557\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1558\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\trainer.py:1835\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1832\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m   1834\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1835\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[0;32m   1837\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1838\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1839\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1840\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1841\u001b[0m ):\n\u001b[0;32m   1842\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1843\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\trainer.py:2690\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2688\u001b[0m         scaled_loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m   2689\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2690\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mbackward(loss)\n\u001b[0;32m   2692\u001b[0m \u001b[39mreturn\u001b[39;00m loss\u001b[39m.\u001b[39mdetach() \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\accelerate\\accelerator.py:1923\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   1921\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscaler\u001b[39m.\u001b[39mscale(loss)\u001b[39m.\u001b[39mbackward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1922\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1923\u001b[0m     loss\u001b[39m.\u001b[39mbackward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./results/checkpoint-7000\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_path, num_labels = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me more\n",
      "0.7907435297966003 || Counter: This node relates to counting or tallying various items or values, making it useful for inventory management or statistical queries.\n",
      "0.6874837279319763 || Up Button: A sub-node of \"Counter,\" it signifies an action of incrementing or moving upwards in numerical count.\n",
      "0.7884219884872437 || Down Button: Another sub-node of \"Counter,\" it denotes an action of decrementing or moving downwards in numerical count.\n"
     ]
    }
   ],
   "source": [
    "a = [\"Counter: This node relates to counting or tallying various items or values, making it useful for inventory management or statistical queries.\", 'Up Button: A sub-node of \"Counter,\" it signifies an action of incrementing or moving upwards in numerical count.', 'Down Button: Another sub-node of \"Counter,\" it denotes an action of decrementing or moving downwards in numerical count.']\n",
    "\n",
    "inp = \"Give me more\"\n",
    "print(inp)\n",
    "\n",
    "for x in a:\n",
    "    inputs = tokenizer(x,inp,return_tensors='pt').to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    prediction = logits.sigmoid()\n",
    "\n",
    "    print(f'{prediction[0].item()} || {x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.predict(test_dataset=tokenizedTestDataset)\n",
    "\n",
    "# Get predictions\n",
    "test_predictions = trainer.predict(tokenizedTestDataset)\n",
    "# Extract the predictions and labels from the result object\n",
    "predictions = test_predictions.predictions\n",
    "labels = test_predictions.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in test_predictions.predictions:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa09182ad644307a5ae7b25a28d42f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[231], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m pearsonr\n\u001b[0;32m      3\u001b[0m \u001b[39m# Predictions\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m predictions \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mpredict(tokenizedValidationDataset)\n\u001b[0;32m      5\u001b[0m predicted_scores \u001b[39m=\u001b[39m predictions\u001b[39m.\u001b[39mpredictions\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m      7\u001b[0m \u001b[39m# True labels\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\trainer.py:3044\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[1;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3041\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m   3043\u001b[0m eval_loop \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprediction_loop \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39muse_legacy_prediction_loop \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 3044\u001b[0m output \u001b[39m=\u001b[39m eval_loop(\n\u001b[0;32m   3045\u001b[0m     test_dataloader, description\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPrediction\u001b[39;49m\u001b[39m\"\u001b[39;49m, ignore_keys\u001b[39m=\u001b[39;49mignore_keys, metric_key_prefix\u001b[39m=\u001b[39;49mmetric_key_prefix\n\u001b[0;32m   3046\u001b[0m )\n\u001b[0;32m   3047\u001b[0m total_batch_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39meval_batch_size \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mworld_size\n\u001b[0;32m   3048\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmetric_key_prefix\u001b[39m}\u001b[39;00m\u001b[39m_jit_compilation_time\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m output\u001b[39m.\u001b[39mmetrics:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\trainer.py:3179\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   3173\u001b[0m     inputs_host \u001b[39m=\u001b[39m (\n\u001b[0;32m   3174\u001b[0m         inputs_decode\n\u001b[0;32m   3175\u001b[0m         \u001b[39mif\u001b[39;00m inputs_host \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   3176\u001b[0m         \u001b[39melse\u001b[39;00m nested_concat(inputs_host, inputs_decode, padding_index\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[0;32m   3177\u001b[0m     )\n\u001b[0;32m   3178\u001b[0m \u001b[39mif\u001b[39;00m logits \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 3179\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maccelerator\u001b[39m.\u001b[39;49mpad_across_processes(logits, dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, pad_index\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[0;32m   3180\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess_logits_for_metrics \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3181\u001b[0m         logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocess_logits_for_metrics(logits, labels)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\accelerate\\accelerator.py:2176\u001b[0m, in \u001b[0;36mAccelerator.pad_across_processes\u001b[1;34m(self, tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[0;32m   2143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpad_across_processes\u001b[39m(\u001b[39mself\u001b[39m, tensor, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, pad_index\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, pad_first\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   2144\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2145\u001b[0m \u001b[39m    Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so\u001b[39;00m\n\u001b[0;32m   2146\u001b[0m \u001b[39m    they can safely be gathered.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2174\u001b[0m \u001b[39m    ```\u001b[39;00m\n\u001b[0;32m   2175\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2176\u001b[0m     \u001b[39mreturn\u001b[39;00m pad_across_processes(tensor, dim\u001b[39m=\u001b[39;49mdim, pad_index\u001b[39m=\u001b[39;49mpad_index, pad_first\u001b[39m=\u001b[39;49mpad_first)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\accelerate\\utils\\operations.py:345\u001b[0m, in \u001b[0;36mchained_operation.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[39m@wraps\u001b[39m(function)\n\u001b[0;32m    343\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    344\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 345\u001b[0m         \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    346\u001b[0m     \u001b[39mexcept\u001b[39;00m DistributedOperationException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    347\u001b[0m         operation \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunction\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mfunction\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\accelerate\\utils\\operations.py:544\u001b[0m, in \u001b[0;36mpad_across_processes\u001b[1;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[0;32m    541\u001b[0m     new_tensor[indices] \u001b[39m=\u001b[39m tensor\n\u001b[0;32m    542\u001b[0m     \u001b[39mreturn\u001b[39;00m new_tensor\n\u001b[1;32m--> 544\u001b[0m \u001b[39mreturn\u001b[39;00m recursively_apply(\n\u001b[0;32m    545\u001b[0m     _pad_across_processes, tensor, error_on_other_type\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, dim\u001b[39m=\u001b[39;49mdim, pad_index\u001b[39m=\u001b[39;49mpad_index, pad_first\u001b[39m=\u001b[39;49mpad_first\n\u001b[0;32m    546\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\accelerate\\utils\\operations.py:128\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[1;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(data)(\n\u001b[0;32m    120\u001b[0m         {\n\u001b[0;32m    121\u001b[0m             k: recursively_apply(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    125\u001b[0m         }\n\u001b[0;32m    126\u001b[0m     )\n\u001b[0;32m    127\u001b[0m \u001b[39melif\u001b[39;00m test_type(data):\n\u001b[1;32m--> 128\u001b[0m     \u001b[39mreturn\u001b[39;00m func(data, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    129\u001b[0m \u001b[39melif\u001b[39;00m error_on_other_type:\n\u001b[0;32m    130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    131\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnsupported types (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) passed to `\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m`. Only nested list/tuple/dicts of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    132\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mobjects that are valid for `\u001b[39m\u001b[39m{\u001b[39;00mtest_type\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m` should be passed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    133\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\accelerate\\utils\\operations.py:524\u001b[0m, in \u001b[0;36mpad_across_processes.<locals>._pad_across_processes\u001b[1;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\n\u001b[0;32m    523\u001b[0m \u001b[39m# Gather all sizes\u001b[39;00m\n\u001b[1;32m--> 524\u001b[0m size \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(tensor\u001b[39m.\u001b[39;49mshape, device\u001b[39m=\u001b[39;49mtensor\u001b[39m.\u001b[39;49mdevice)[\u001b[39mNone\u001b[39;00m]\n\u001b[0;32m    525\u001b[0m sizes \u001b[39m=\u001b[39m gather(size)\u001b[39m.\u001b[39mcpu()\n\u001b[0;32m    526\u001b[0m \u001b[39m# Then pad to the maximum size\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Predictions\n",
    "predictions = trainer.predict(tokenizedValidationDataset)\n",
    "predicted_scores = predictions.predictions.flatten()\n",
    "\n",
    "# True labels\n",
    "true_scores = predictions.label_ids\n",
    "\n",
    "# Pearson Correlation\n",
    "corr, _ = pearsonr(true_scores, predicted_scores)\n",
    "\n",
    "print(f'Pearson Correlation: {corr}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(true_scores, predicted_scores)\n",
    "print(f'Mean Squared Error: {mse}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train even more, let's overfit why not. Overfitting = Low Test Loss = Happy Investors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Training Arguments\n",
    "trainingArgs = TrainingArguments(\n",
    "    output_dir= \"./results\",\n",
    "    num_train_epochs= 4,\n",
    "    per_device_eval_batch_size= 4,\n",
    "    per_device_train_batch_size= 4,\n",
    "    evaluation_strategy= \"epoch\",\n",
    "    logging_dir = \"./logs\",\n",
    "    do_train = True,\n",
    "    do_eval = True,\n",
    "    learning_rate = 2e-5,\n",
    "    warmup_ratio=0.1,\n",
    ")\n",
    "\n",
    "# Configure Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=trainingArgs,\n",
    "    train_dataset=tokenizedTrainDataset,\n",
    "    eval_dataset= tokenizedValidationDataset,\n",
    "    compute_metrics=lambda eval_preds: {\"mse\": ((eval_preds.predictions - eval_preds.label_ids) ** 2).mean()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd4de27d0ea48569a9223cd6db03856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation: 0.884903959934462\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Predictions\n",
    "predictions = trainer.predict(tokenizedValidationDataset)\n",
    "predicted_scores = predictions.predictions.flatten()\n",
    "\n",
    "# True labels\n",
    "true_scores = predictions.label_ids\n",
    "\n",
    "# Pearson Correlation\n",
    "corr, _ = pearsonr(true_scores, predicted_scores)\n",
    "\n",
    "print(f'Pearson Correlation: {corr}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.5120729804039001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(true_scores, predicted_scores)\n",
    "print(f'Mean Squared Error: {mse}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
